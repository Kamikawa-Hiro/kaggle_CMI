{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":102335,"databundleVersionId":12518947,"sourceType":"competition"},{"sourceId":242954653,"sourceType":"kernelVersion"}],"dockerImageVersionId":31041,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**This solution was developed by building upon the foundational work of two key contributors:**\n\n- **CMI25 | IMU+THM/TOF |TF BiLSTM+GRU+Attention|LB.75** by [yukiZ](https://www.kaggle.com/code/hideyukizushi/cmi25-imu-thm-tof-tf-bilstm-gru-attention-lb-75)\n- **imu-tof** by [Erich von Mainstein](https://www.kaggle.com/code/vonmainstein/imu-tof)\n\n**Special recognition for the exceptional exploratory data analysis:**\n\n- **Sensor PulseğŸ§ | Viz & EDA for BFRB Detection** by [Tarun Mishra](https://www.kaggle.com/code/tarundirector/sensor-pulse-viz-eda-for-bfrb-detection)\n\n### Implemented Enhancements\n\n#### 1. IMU Signal Processing Optimization (Core Improvement)\n\n**Implemented Features:**\n- Derived kinematic metrics:\n  - Acceleration vector magnitude (`acc_mag`)\n  - Scalar rotation angle (`rot_angle`)\n  - Acceleration derivative (`acc_mag_jerk`)\n  - Angular velocity (`rot_angle_vel`)\n- Initial learning rate reduction from `1e-3` to `5e-4`\n- Implemented cosine decay scheduling:\n  - Parameters: `first_decay_steps = 15 Ã— steps_per_epoch`\n\n**Unsuccessful Experiments (Reverted):**\n- Further LR Reduction: `LR_INIT = 2-e4` worsened score.\n- Dropout Rate Adjustments: No improvement over baseline dropout.\n- TOF/THEM Branch Architecture Change: Replacing simpler CNNs with `residual_se_cnn_blocks` was detrimental.\n\n**If you support the notebook, please upvoteâ€”Iâ€™d really appreciate it!**  \n**Also, if you have any questions, feel free to askâ€”Iâ€™ll be happy to answer. ğŸ˜Š**","metadata":{}},{"cell_type":"markdown","source":"### ã€‹ã€‹ã€‹**Importing the necessary Libraries**","metadata":{}},{"cell_type":"code","source":"import os, json, joblib, numpy as np, pandas as pd\nfrom pathlib import Path\nimport warnings \nwarnings.filterwarnings(\"ignore\")\n\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom sklearn.utils.class_weight import compute_class_weight\n\nfrom tensorflow.keras.utils import Sequence, to_categorical, pad_sequences\nfrom tensorflow.keras.models import Model, load_model\nfrom tensorflow.keras.layers import (\n    Input, Conv1D, BatchNormalization, Activation, add, MaxPooling1D, Dropout,\n    Bidirectional, LSTM, GlobalAveragePooling1D, Dense, Multiply, Reshape,\n    Lambda, Concatenate, GRU, GaussianNoise\n)\nfrom tensorflow.keras.regularizers import l2\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras import backend as K\nimport tensorflow as tf\nimport polars as pl\nfrom sklearn.model_selection import StratifiedGroupKFold\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-14T12:41:49.607009Z","iopub.execute_input":"2025-06-14T12:41:49.607177Z","iopub.status.idle":"2025-06-14T12:42:05.490391Z","shell.execute_reply.started":"2025-06-14T12:41:49.607162Z","shell.execute_reply":"2025-06-14T12:42:05.489591Z"}},"outputs":[{"name":"stderr","text":"2025-06-14 12:41:53.708003: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1749904913.918692      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1749904913.982048      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"### ã€‹ã€‹ã€‹**Fix Seed**","metadata":{}},{"cell_type":"code","source":"import random\ndef seed_everything(seed):\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    random.seed(seed)\n    np.random.seed(seed)\n    tf.random.set_seed(seed)\n    tf.experimental.numpy.random.seed(seed)\n    os.environ['TF_CUDNN_DETERMINISTIC'] = '1'\n    os.environ['TF_DETERMINISTIC_OPS'] = '1'\nseed_everything(seed=42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-14T12:42:05.491260Z","iopub.execute_input":"2025-06-14T12:42:05.491682Z","iopub.status.idle":"2025-06-14T12:42:05.496221Z","shell.execute_reply.started":"2025-06-14T12:42:05.491663Z","shell.execute_reply":"2025-06-14T12:42:05.495491Z"}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"### ã€‹ã€‹ã€‹**Configuration**","metadata":{}},{"cell_type":"code","source":"# (Competition metric will only be imported when TRAINing)\nTRAIN = True                     # â† set to True when you want to train\nRAW_DIR = Path(\"/kaggle/input/cmi-detect-behavior-with-sensor-data\")\nPRETRAINED_DIR = Path(\"/kaggle/input/pretrained-model\")  # used when TRAIN=False\nEXPORT_DIR = Path(\"./\")                                    # artefacts will be saved here\nBATCH_SIZE = 64\nPAD_PERCENTILE = 95\nLR_INIT = 5e-4\nWD = 3e-3\nMIXUP_ALPHA = 0.4\nEPOCHS = 160\nPATIENCE = 40\n\n\nprint(\"â–¶ imports ready Â· tensorflow\", tf.__version__)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-14T12:42:05.498111Z","iopub.execute_input":"2025-06-14T12:42:05.498580Z","iopub.status.idle":"2025-06-14T12:42:05.520540Z","shell.execute_reply.started":"2025-06-14T12:42:05.498562Z","shell.execute_reply":"2025-06-14T12:42:05.519841Z"}},"outputs":[{"name":"stdout","text":"â–¶ imports ready Â· tensorflow 2.18.0\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"### ã€‹ã€‹ã€‹**Utility Functions**","metadata":{}},{"cell_type":"code","source":"#Tensor Manipulations\ndef time_sum(x):\n    return K.sum(x, axis=1)\n\ndef squeeze_last_axis(x):\n    return tf.squeeze(x, axis=-1)\n\ndef expand_last_axis(x):\n    return tf.expand_dims(x, axis=-1)\n\ndef se_block(x, reduction=8):\n    ch = x.shape[-1]\n    se = GlobalAveragePooling1D()(x)\n    se = Dense(ch // reduction, activation='relu')(se)\n    se = Dense(ch, activation='sigmoid')(se)\n    se = Reshape((1, ch))(se)\n    return Multiply()([x, se])\n\n# Residual CNN Block with SE\ndef residual_se_cnn_block(x, filters, kernel_size, pool_size=2, drop=0.3, wd=1e-4):\n    shortcut = x\n    for _ in range(2):\n        x = Conv1D(filters, kernel_size, padding='same', use_bias=False,\n                   kernel_regularizer=l2(wd))(x)\n        x = BatchNormalization()(x)\n        x = Activation('relu')(x)\n    x = se_block(x)\n    if shortcut.shape[-1] != filters:\n        shortcut = Conv1D(filters, 1, padding='same', use_bias=False,\n                          kernel_regularizer=l2(wd))(shortcut)\n        shortcut = BatchNormalization()(shortcut)\n    x = add([x, shortcut])\n    x = Activation('relu')(x)\n    x = MaxPooling1D(pool_size)(x)\n    x = Dropout(drop)(x)\n    return x\n\ndef attention_layer(inputs):\n    score = Dense(1, activation='tanh')(inputs)\n    score = Lambda(squeeze_last_axis)(score)\n    weights = Activation('softmax')(score)\n    weights = Lambda(expand_last_axis)(weights)\n    context = Multiply()([inputs, weights])\n    context = Lambda(time_sum)(context)\n    return context","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-14T12:42:05.521107Z","iopub.execute_input":"2025-06-14T12:42:05.521282Z","iopub.status.idle":"2025-06-14T12:42:05.532310Z","shell.execute_reply.started":"2025-06-14T12:42:05.521267Z","shell.execute_reply":"2025-06-14T12:42:05.531639Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"### ã€‹ã€‹ã€‹**Data Helpers**","metadata":{}},{"cell_type":"code","source":"# Normalizes and cleans the time series sequence. \n\ndef preprocess_sequence(df_seq: pd.DataFrame, feature_cols: list[str], scaler: StandardScaler):\n    mat = df_seq[feature_cols].ffill().bfill().fillna(0).values\n    return scaler.transform(mat).astype('float32')\n\n# MixUp the data argumentation in order to regularize the neural network. \n\nclass MixupGenerator(Sequence):\n    def __init__(self, X, y, batch_size, alpha=0.2):\n        self.X, self.y = X, y\n        self.batch = batch_size\n        self.alpha = alpha\n        self.indices = np.arange(len(X))\n    def __len__(self):\n        return int(np.ceil(len(self.X) / self.batch))\n    def __getitem__(self, i):\n        idx = self.indices[i*self.batch:(i+1)*self.batch]\n        Xb, yb = self.X[idx], self.y[idx]\n        lam = np.random.beta(self.alpha, self.alpha)\n        perm = np.random.permutation(len(Xb))\n        X_mix = lam * Xb + (1-lam) * Xb[perm]\n        y_mix = lam * yb + (1-lam) * yb[perm]\n        return X_mix, y_mix\n    def on_epoch_end(self):\n        np.random.shuffle(self.indices)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-14T12:42:05.533033Z","iopub.execute_input":"2025-06-14T12:42:05.533251Z","iopub.status.idle":"2025-06-14T12:42:05.552186Z","shell.execute_reply.started":"2025-06-14T12:42:05.533227Z","shell.execute_reply":"2025-06-14T12:42:05.551451Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"### ã€‹ã€‹ã€‹**Model Definition - Two Branch Architecture**","metadata":{}},{"cell_type":"code","source":"def build_two_branch_model(pad_len, imu_dim, tof_dim, n_classes, wd=1e-4):\n    inp = Input(shape=(pad_len, imu_dim+tof_dim))\n    imu = Lambda(lambda t: t[:, :, :imu_dim])(inp)\n    tof = Lambda(lambda t: t[:, :, imu_dim:])(inp)\n\n    # IMU deep branch\n    x1 = residual_se_cnn_block(imu, 64, 3, drop=0.1, wd=wd)\n    x1 = residual_se_cnn_block(x1, 128, 5, drop=0.1, wd=wd)\n\n    # TOF/Thermal lighter branch\n    x2 = Conv1D(64, 3, padding='same', use_bias=False, kernel_regularizer=l2(wd))(tof)\n    x2 = BatchNormalization()(x2); x2 = Activation('relu')(x2)\n    x2 = MaxPooling1D(2)(x2); x2 = Dropout(0.2)(x2)\n    x2 = Conv1D(128, 3, padding='same', use_bias=False, kernel_regularizer=l2(wd))(x2)\n    x2 = BatchNormalization()(x2); x2 = Activation('relu')(x2)\n    x2 = MaxPooling1D(2)(x2); x2 = Dropout(0.2)(x2)\n\n    merged = Concatenate()([x1, x2])\n\n    xa = Bidirectional(LSTM(128, return_sequences=True, kernel_regularizer=l2(wd)))(merged)\n    xb = Bidirectional(GRU(128, return_sequences=True, kernel_regularizer=l2(wd)))(merged)\n    xc = GaussianNoise(0.09)(merged)\n    xc = Dense(16, activation='elu')(xc)\n    \n    x = Concatenate()([xa, xb, xc])\n    x = Dropout(0.4)(x)\n    x = attention_layer(x)\n\n    for units, drop in [(256, 0.5), (128, 0.3)]:\n        x = Dense(units, use_bias=False, kernel_regularizer=l2(wd))(x)\n        x = BatchNormalization()(x); x = Activation('relu')(x)\n        x = Dropout(drop)(x)\n\n    out = Dense(n_classes, activation='softmax', kernel_regularizer=l2(wd))(x)\n    return Model(inp, out)\n\ntmp_model = build_two_branch_model(127,7,325,18)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-14T12:42:05.552907Z","iopub.execute_input":"2025-06-14T12:42:05.553097Z","iopub.status.idle":"2025-06-14T12:42:08.493646Z","shell.execute_reply.started":"2025-06-14T12:42:05.553083Z","shell.execute_reply":"2025-06-14T12:42:08.493117Z"}},"outputs":[{"name":"stderr","text":"I0000 00:00:1749904926.866808      35 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15513 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"### ã€‹ã€‹ã€‹**Training / Inference Pipeline**","metadata":{}},{"cell_type":"code","source":"if TRAIN:\n    print(\"â–¶ TRAIN MODE â€“ loading dataset â€¦\")\n    df = pd.read_csv(RAW_DIR / \"train.csv\")\n\n    train_dem_df = pd.read_csv(RAW_DIR / \"train_demographics.csv\")\n    df_for_groups = pd.merge(df.copy(), train_dem_df, on='subject', how='left')\n\n    le = LabelEncoder()\n    df['gesture_int'] = le.fit_transform(df['gesture'])\n    np.save(EXPORT_DIR / \"gesture_classes.npy\", le.classes_)\n    gesture_classes = le.classes_\n\n    print(\"  Calculating engineered IMU features (magnitude, angle)...\")\n    df['acc_mag'] = np.sqrt(df['acc_x']**2 + df['acc_y']**2 + df['acc_z']**2)\n    df['rot_angle'] = 2 * np.arccos(df['rot_w'].clip(-1, 1))\n    \n    print(\"  Calculating engineered IMU derivatives (jerk, angular velocity)...\")\n    df['acc_mag_jerk'] = df.groupby('sequence_id')['acc_mag'].diff().fillna(0)\n    df['rot_angle_vel'] = df.groupby('sequence_id')['rot_angle'].diff().fillna(0)\n\n    meta_cols = {'gesture', 'gesture_int', 'sequence_type', 'behavior', 'orientation',\n                 'row_id', 'subject', 'phase', 'sequence_id', 'sequence_counter'}\n\n    imu_cols = [c for c in df.columns if c.startswith('acc_') and c not in ['acc_mag', 'acc_mag_jerk']]\n    imu_cols.extend([c for c in df.columns if c.startswith('rot_') and c not in ['rot_angle', 'rot_angle_vel']])\n    imu_cols.extend(['acc_mag', 'rot_angle', 'acc_mag_jerk', 'rot_angle_vel'])\n\n    thm_cols_original = [c for c in df.columns if c.startswith('thm_')]\n    \n    tof_aggregated_cols_template = []\n    for i in range(1, 6):\n        tof_aggregated_cols_template.extend([f'tof_{i}_mean', f'tof_{i}_std', f'tof_{i}_min', f'tof_{i}_max'])\n\n    final_feature_cols = imu_cols + thm_cols_original + tof_aggregated_cols_template\n    imu_dim_final = len(imu_cols)\n    tof_thm_aggregated_dim_final = len(thm_cols_original) + len(tof_aggregated_cols_template)\n    \n    print(f\"  IMU (incl. engineered & derivatives) {imu_dim_final} | THM + Aggregated TOF {tof_thm_aggregated_dim_final} | total {len(final_feature_cols)} features\")\n    np.save(EXPORT_DIR / \"feature_cols.npy\", np.array(final_feature_cols))\n\n    print(\"  Building sequences with aggregated TOF and preparing data for scaler...\")\n    seq_gp = df.groupby('sequence_id') \n    \n    all_steps_for_scaler_list = []\n    X_list_unscaled, y_list_int_for_stratify, lens = [], [], [] \n\n    for seq_id, seq_df_orig in seq_gp:\n        seq_df = seq_df_orig.copy()\n\n        for i in range(1, 6):\n            pixel_cols_tof = [f\"tof_{i}_v{p}\" for p in range(64)]\n            tof_sensor_data = seq_df[pixel_cols_tof].replace(-1, np.nan)\n            seq_df[f'tof_{i}_mean'] = tof_sensor_data.mean(axis=1)\n            seq_df[f'tof_{i}_std']  = tof_sensor_data.std(axis=1)\n            seq_df[f'tof_{i}_min']  = tof_sensor_data.min(axis=1)\n            seq_df[f'tof_{i}_max']  = tof_sensor_data.max(axis=1)\n        \n        mat_unscaled = seq_df[final_feature_cols].ffill().bfill().fillna(0).values.astype('float32')\n        \n        all_steps_for_scaler_list.append(mat_unscaled)\n        X_list_unscaled.append(mat_unscaled)\n        y_list_int_for_stratify.append(seq_df['gesture_int'].iloc[0])\n        lens.append(len(mat_unscaled))\n\n    print(\"  Fitting StandardScaler...\")\n    all_steps_concatenated = np.concatenate(all_steps_for_scaler_list, axis=0)\n    scaler = StandardScaler().fit(all_steps_concatenated)\n    joblib.dump(scaler, EXPORT_DIR / \"scaler.pkl\")\n    del all_steps_for_scaler_list, all_steps_concatenated\n\n    print(\"  Scaling and padding sequences...\")\n    X_scaled_list = [scaler.transform(x_seq) for x_seq in X_list_unscaled]\n    del X_list_unscaled\n\n    pad_len = int(np.percentile(lens, PAD_PERCENTILE))\n    np.save(EXPORT_DIR / \"sequence_maxlen.npy\", pad_len)\n    \n    X = pad_sequences(X_scaled_list, maxlen=pad_len, padding='post', truncating='post', dtype='float32')\n    del X_scaled_list\n    \n    y_int_for_stratify = np.array(y_list_int_for_stratify)\n    y = to_categorical(y_int_for_stratify, num_classes=len(le.classes_))\n\n    print(\"  Splitting data and preparing for training...\")\n    X_tr, X_val, y_tr, y_val = train_test_split(X, y, test_size=0.1, random_state=82, stratify=y_int_for_stratify)\n\n    cw_vals = compute_class_weight('balanced', classes=np.arange(len(le.classes_)), y=y_int_for_stratify)\n    class_weight = dict(enumerate(cw_vals))\n\n    model = build_two_branch_model(pad_len, imu_dim_final, tof_thm_aggregated_dim_final, len(le.classes_), wd=WD)\n    \n    steps = len(X_tr) // BATCH_SIZE\n    lr_sched = tf.keras.optimizers.schedules.CosineDecayRestarts(5e-4, first_decay_steps=15 * steps) \n    \n    model.compile(optimizer=Adam(lr_sched),\n                  loss=tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.1),\n                  metrics=['accuracy'])\n\n    train_gen = MixupGenerator(X_tr, y_tr, batch_size=BATCH_SIZE, alpha=MIXUP_ALPHA)\n    cb = EarlyStopping(patience=PATIENCE, restore_best_weights=True, verbose=1, monitor='val_accuracy', mode='max')\n    \n    print(\"  Starting model training...\")\n    model.fit(train_gen, epochs=EPOCHS, validation_data=(X_val, y_val),\n              class_weight=class_weight, callbacks=[cb], verbose=1)\n\n    model.save(EXPORT_DIR / \"gesture_two_branch_mixup.h5\")\n    print(\"âœ” Training done â€“ artefacts saved in\", EXPORT_DIR)\n\n    from cmi_2025_metric_copy_for_import import CompetitionMetric\n    preds_val = model.predict(X_val).argmax(1)\n    true_val_int  = y_val.argmax(1)\n    \n    h_f1 = CompetitionMetric().calculate_hierarchical_f1(\n        pd.DataFrame({'gesture': le.classes_[true_val_int]}),\n        pd.DataFrame({'gesture': le.classes_[preds_val]}))\n    print(\"Holdâ€‘out Hâ€‘F1 =\", round(h_f1, 4))\n\nelse:\n    print(\"â–¶ INFERENCE MODE â€“ loading artefacts from\", PRETRAINED_DIR)\n    final_feature_cols = np.load(PRETRAINED_DIR / \"feature_cols.npy\", allow_pickle=True).tolist()\n    pad_len        = int(np.load(PRETRAINED_DIR / \"sequence_maxlen.npy\"))\n    scaler         = joblib.load(PRETRAINED_DIR / \"scaler.pkl\")\n    gesture_classes = np.load(PRETRAINED_DIR / \"gesture_classes.npy\", allow_pickle=True)\n\n    temp_imu_cols = [c for c in final_feature_cols if c.startswith('acc_') or c.startswith('rot_')]\n    imu_dim_final = len(temp_imu_cols)\n    tof_thm_aggregated_dim_final = len(final_feature_cols) - imu_dim_final\n\n    custom_objs = {\n        'time_sum': time_sum,\n        'squeeze_last_axis': squeeze_last_axis,\n        'expand_last_axis': expand_last_axis,\n        'se_block': se_block,\n        'residual_se_cnn_block': residual_se_cnn_block,\n        'attention_layer': attention_layer,\n    }\n    model = load_model(PRETRAINED_DIR / \"gesture_two_branch_mixup.h5\",\n                       compile=False, custom_objects=custom_objs)\n    print(\"  Model, scaler, feature_cols, pad_len loaded â€“ ready for evaluation\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-14T12:42:08.494381Z","iopub.execute_input":"2025-06-14T12:42:08.494560Z","iopub.status.idle":"2025-06-14T12:55:14.766220Z","shell.execute_reply.started":"2025-06-14T12:42:08.494545Z","shell.execute_reply":"2025-06-14T12:55:14.765560Z"},"scrolled":true},"outputs":[{"name":"stdout","text":"â–¶ TRAIN MODE â€“ loading dataset â€¦\n  Calculating engineered IMU features (magnitude, angle)...\n  Calculating engineered IMU derivatives (jerk, angular velocity)...\n  IMU (incl. engineered & derivatives) 11 | THM + Aggregated TOF 25 | total 36 features\n  Building sequences with aggregated TOF and preparing data for scaler...\n  Fitting StandardScaler...\n  Scaling and padding sequences...\n  Splitting data and preparing for training...\n  Starting model training...\nEpoch 1/160\n","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1749905099.141049      97 cuda_dnn.cc:529] Loaded cuDNN version 90300\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m114/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.1288 - loss: 9.6306","output_type":"stream"},{"name":"stderr","text":"2025-06-14 12:45:06.362925: E tensorflow/core/framework/node_def_util.cc:676] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_15}}\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 51ms/step - accuracy: 0.1297 - loss: 9.6183 - val_accuracy: 0.3640 - val_loss: 7.6035\nEpoch 2/160\n\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.2731 - loss: 7.2963 - val_accuracy: 0.4338 - val_loss: 5.9587\nEpoch 3/160\n\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.3273 - loss: 5.9918 - val_accuracy: 0.4681 - val_loss: 5.0041\nEpoch 4/160\n\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.3919 - loss: 5.1216 - val_accuracy: 0.5000 - val_loss: 4.3272\nEpoch 5/160\n\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.4129 - loss: 4.6420 - val_accuracy: 0.5037 - val_loss: 3.9037\nEpoch 6/160\n\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.4477 - loss: 4.1739 - val_accuracy: 0.5453 - val_loss: 3.5924\nEpoch 7/160\n\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.4879 - loss: 3.8546 - val_accuracy: 0.5600 - val_loss: 3.3447\nEpoch 8/160\n\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.4864 - loss: 3.6232 - val_accuracy: 0.5368 - val_loss: 3.2365\nEpoch 9/160\n\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.4996 - loss: 3.4985 - val_accuracy: 0.5797 - val_loss: 3.0236\nEpoch 10/160\n\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.5253 - loss: 3.3901 - val_accuracy: 0.5956 - val_loss: 2.9266\nEpoch 11/160\n\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.5388 - loss: 3.2607 - val_accuracy: 0.6005 - val_loss: 2.8420\nEpoch 12/160\n\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.5408 - loss: 3.2406 - val_accuracy: 0.6042 - val_loss: 2.7920\nEpoch 13/160\n\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.5547 - loss: 3.1443 - val_accuracy: 0.6127 - val_loss: 2.7756\nEpoch 14/160\n\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.5538 - loss: 3.1354 - val_accuracy: 0.6152 - val_loss: 2.7618\nEpoch 15/160\n\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.5654 - loss: 3.0717 - val_accuracy: 0.5527 - val_loss: 2.9074\nEpoch 16/160\n\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.5111 - loss: 3.1938 - val_accuracy: 0.5539 - val_loss: 2.7618\nEpoch 17/160\n\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.4975 - loss: 3.0271 - val_accuracy: 0.5919 - val_loss: 2.5143\nEpoch 18/160\n\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.5380 - loss: 2.7881 - val_accuracy: 0.5870 - val_loss: 2.4043\nEpoch 19/160\n\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.5302 - loss: 2.6430 - val_accuracy: 0.6054 - val_loss: 2.2273\nEpoch 20/160\n\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.5484 - loss: 2.5724 - val_accuracy: 0.6115 - val_loss: 2.1701\nEpoch 21/160\n\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.5428 - loss: 2.5355 - val_accuracy: 0.6164 - val_loss: 2.0888\nEpoch 22/160\n\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.5702 - loss: 2.4007 - val_accuracy: 0.6054 - val_loss: 2.0815\nEpoch 23/160\n\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.5577 - loss: 2.4178 - val_accuracy: 0.6164 - val_loss: 1.9520\nEpoch 24/160\n\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.5827 - loss: 2.2081 - val_accuracy: 0.6029 - val_loss: 1.9654\nEpoch 25/160\n\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.5916 - loss: 2.1653 - val_accuracy: 0.6201 - val_loss: 1.8727\nEpoch 26/160\n\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.5747 - loss: 2.2186 - val_accuracy: 0.6287 - val_loss: 1.8325\nEpoch 27/160\n\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.6018 - loss: 2.1088 - val_accuracy: 0.6409 - val_loss: 1.8138\nEpoch 28/160\n\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.6094 - loss: 2.1430 - val_accuracy: 0.6471 - val_loss: 1.7891\nEpoch 29/160\n\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 39ms/step - accuracy: 0.6009 - loss: 2.0261 - val_accuracy: 0.6544 - val_loss: 1.7263\nEpoch 30/160\n\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.6254 - loss: 2.0667 - val_accuracy: 0.6483 - val_loss: 1.7661\nEpoch 31/160\n\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.6321 - loss: 2.0338 - val_accuracy: 0.6777 - val_loss: 1.6844\nEpoch 32/160\n\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.6235 - loss: 1.9992 - val_accuracy: 0.6581 - val_loss: 1.6503\nEpoch 33/160\n\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.6293 - loss: 2.0691 - val_accuracy: 0.6532 - val_loss: 1.6409\nEpoch 34/160\n\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.6445 - loss: 1.9467 - val_accuracy: 0.6936 - val_loss: 1.5835\nEpoch 35/160\n\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.6711 - loss: 1.8575 - val_accuracy: 0.6801 - val_loss: 1.5928\nEpoch 36/160\n\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.6612 - loss: 1.9043 - val_accuracy: 0.6691 - val_loss: 1.5965\nEpoch 37/160\n\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.6729 - loss: 1.8986 - val_accuracy: 0.7194 - val_loss: 1.5315\nEpoch 38/160\n\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.6775 - loss: 1.8898 - val_accuracy: 0.7132 - val_loss: 1.5214\nEpoch 39/160\n\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.7140 - loss: 1.7628 - val_accuracy: 0.7206 - val_loss: 1.5054\nEpoch 40/160\n\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.6974 - loss: 1.8517 - val_accuracy: 0.7120 - val_loss: 1.5048\nEpoch 41/160\n\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.7139 - loss: 1.8050 - val_accuracy: 0.7279 - val_loss: 1.4951\nEpoch 42/160\n\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.6878 - loss: 1.8902 - val_accuracy: 0.7169 - val_loss: 1.4969\nEpoch 43/160\n\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.7096 - loss: 1.8161 - val_accuracy: 0.7181 - val_loss: 1.4899\nEpoch 44/160\n\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.7065 - loss: 1.8636 - val_accuracy: 0.7157 - val_loss: 1.4894\nEpoch 45/160\n\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.7197 - loss: 1.7519 - val_accuracy: 0.5662 - val_loss: 1.9706\nEpoch 46/160\n\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.5835 - loss: 2.0109 - val_accuracy: 0.6189 - val_loss: 1.7521\nEpoch 47/160\n\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.5754 - loss: 2.0548 - val_accuracy: 0.6360 - val_loss: 1.6683\nEpoch 48/160\n\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.6060 - loss: 2.0133 - val_accuracy: 0.6311 - val_loss: 1.7032\nEpoch 49/160\n\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.6172 - loss: 1.9277 - val_accuracy: 0.6373 - val_loss: 1.7508\nEpoch 50/160\n\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.6229 - loss: 1.9507 - val_accuracy: 0.6630 - val_loss: 1.6961\nEpoch 51/160\n\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.6540 - loss: 1.8812 - val_accuracy: 0.6703 - val_loss: 1.6434\nEpoch 52/160\n\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.6391 - loss: 1.8801 - val_accuracy: 0.6250 - val_loss: 1.7029\nEpoch 53/160\n\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.6500 - loss: 1.8488 - val_accuracy: 0.6409 - val_loss: 1.6613\nEpoch 54/160\n\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.6278 - loss: 1.9750 - val_accuracy: 0.6679 - val_loss: 1.6348\nEpoch 55/160\n\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.6520 - loss: 1.8845 - val_accuracy: 0.6716 - val_loss: 1.5975\nEpoch 56/160\n\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.6511 - loss: 1.8599 - val_accuracy: 0.6385 - val_loss: 1.6702\nEpoch 57/160\n\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.6615 - loss: 1.8199 - val_accuracy: 0.6728 - val_loss: 1.5663\nEpoch 58/160\n\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.6491 - loss: 1.8654 - val_accuracy: 0.6201 - val_loss: 1.7145\nEpoch 59/160\n\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.6351 - loss: 1.9067 - val_accuracy: 0.6826 - val_loss: 1.5572\nEpoch 60/160\n\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.6678 - loss: 1.8578 - val_accuracy: 0.6973 - val_loss: 1.5296\nEpoch 61/160\n\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.6739 - loss: 1.8548 - val_accuracy: 0.6458 - val_loss: 1.6598\nEpoch 62/160\n\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.6525 - loss: 1.7958 - val_accuracy: 0.6789 - val_loss: 1.5457\nEpoch 63/160\n\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.6761 - loss: 1.7185 - val_accuracy: 0.6863 - val_loss: 1.5369\nEpoch 64/160\n\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.6625 - loss: 1.8417 - val_accuracy: 0.7010 - val_loss: 1.5097\nEpoch 65/160\n\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.7000 - loss: 1.7415 - val_accuracy: 0.7230 - val_loss: 1.4834\nEpoch 66/160\n\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 39ms/step - accuracy: 0.6817 - loss: 1.7838 - val_accuracy: 0.6924 - val_loss: 1.4851\nEpoch 67/160\n\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.6677 - loss: 1.8234 - val_accuracy: 0.6838 - val_loss: 1.5333\nEpoch 68/160\n\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.7015 - loss: 1.7614 - val_accuracy: 0.6850 - val_loss: 1.4917\nEpoch 69/160\n\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.7020 - loss: 1.7774 - val_accuracy: 0.7047 - val_loss: 1.4926\nEpoch 70/160\n\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.6725 - loss: 1.8981 - val_accuracy: 0.6850 - val_loss: 1.5341\nEpoch 71/160\n\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.7067 - loss: 1.7430 - val_accuracy: 0.7010 - val_loss: 1.4625\nEpoch 72/160\n\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.6995 - loss: 1.8199 - val_accuracy: 0.6998 - val_loss: 1.5028\nEpoch 73/160\n\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.7137 - loss: 1.7244 - val_accuracy: 0.6483 - val_loss: 1.5556\nEpoch 74/160\n\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.7099 - loss: 1.7063 - val_accuracy: 0.7230 - val_loss: 1.3894\nEpoch 75/160\n\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.7133 - loss: 1.6803 - val_accuracy: 0.7353 - val_loss: 1.4147\nEpoch 76/160\n\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.7294 - loss: 1.6287 - val_accuracy: 0.7402 - val_loss: 1.3995\nEpoch 77/160\n\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.7462 - loss: 1.6450 - val_accuracy: 0.7096 - val_loss: 1.3977\nEpoch 78/160\n\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.7178 - loss: 1.7330 - val_accuracy: 0.6924 - val_loss: 1.4670\nEpoch 79/160\n\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.7184 - loss: 1.7524 - val_accuracy: 0.6985 - val_loss: 1.4704\nEpoch 80/160\n\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.7422 - loss: 1.6804 - val_accuracy: 0.7328 - val_loss: 1.3739\nEpoch 81/160\n\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.7474 - loss: 1.6359 - val_accuracy: 0.7451 - val_loss: 1.3828\nEpoch 82/160\n\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.7455 - loss: 1.6544 - val_accuracy: 0.7353 - val_loss: 1.3633\nEpoch 83/160\n\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.7470 - loss: 1.6448 - val_accuracy: 0.7426 - val_loss: 1.3865\nEpoch 84/160\n\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.7395 - loss: 1.6684 - val_accuracy: 0.7414 - val_loss: 1.3472\nEpoch 85/160\n\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.7645 - loss: 1.5763 - val_accuracy: 0.7451 - val_loss: 1.3327\nEpoch 86/160\n\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.7826 - loss: 1.4957 - val_accuracy: 0.7500 - val_loss: 1.3379\nEpoch 87/160\n\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.7747 - loss: 1.5900 - val_accuracy: 0.7426 - val_loss: 1.3481\nEpoch 88/160\n\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.7808 - loss: 1.5821 - val_accuracy: 0.7488 - val_loss: 1.3233\nEpoch 89/160\n\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.8010 - loss: 1.5346 - val_accuracy: 0.7819 - val_loss: 1.2918\nEpoch 90/160\n\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.7936 - loss: 1.5453 - val_accuracy: 0.7402 - val_loss: 1.3164\nEpoch 91/160\n\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.7895 - loss: 1.5637 - val_accuracy: 0.7586 - val_loss: 1.2887\nEpoch 92/160\n\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.8040 - loss: 1.5266 - val_accuracy: 0.7598 - val_loss: 1.2920\nEpoch 93/160\n\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.8007 - loss: 1.5457 - val_accuracy: 0.7659 - val_loss: 1.2826\nEpoch 94/160\n\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.7963 - loss: 1.5937 - val_accuracy: 0.7684 - val_loss: 1.2862\nEpoch 95/160\n\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.7958 - loss: 1.5628 - val_accuracy: 0.7721 - val_loss: 1.2909\nEpoch 96/160\n\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.7802 - loss: 1.5841 - val_accuracy: 0.7757 - val_loss: 1.2865\nEpoch 97/160\n\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.7871 - loss: 1.5909 - val_accuracy: 0.7770 - val_loss: 1.2757\nEpoch 98/160\n\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.7972 - loss: 1.5456 - val_accuracy: 0.7696 - val_loss: 1.2726\nEpoch 99/160\n\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.8207 - loss: 1.4910 - val_accuracy: 0.7831 - val_loss: 1.2611\nEpoch 100/160\n\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.8074 - loss: 1.5349 - val_accuracy: 0.7721 - val_loss: 1.2724\nEpoch 101/160\n\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.8210 - loss: 1.5203 - val_accuracy: 0.7831 - val_loss: 1.2692\nEpoch 102/160\n\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - accuracy: 0.8076 - loss: 1.5584 - val_accuracy: 0.7757 - val_loss: 1.2749\nEpoch 103/160\n\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.8350 - loss: 1.4824 - val_accuracy: 0.7782 - val_loss: 1.2715\nEpoch 104/160\n\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.8023 - loss: 1.5341 - val_accuracy: 0.7770 - val_loss: 1.2700\nEpoch 105/160\n\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.7547 - loss: 1.5840 - val_accuracy: 0.6777 - val_loss: 1.5808\nEpoch 106/160\n\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.6554 - loss: 1.8381 - val_accuracy: 0.6900 - val_loss: 1.5704\nEpoch 107/160\n\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.7127 - loss: 1.7381 - val_accuracy: 0.6054 - val_loss: 1.8205\nEpoch 108/160\n\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.6750 - loss: 1.8556 - val_accuracy: 0.6642 - val_loss: 1.5896\nEpoch 109/160\n\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.6839 - loss: 1.8467 - val_accuracy: 0.6863 - val_loss: 1.5356\nEpoch 110/160\n\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.6844 - loss: 1.7901 - val_accuracy: 0.6961 - val_loss: 1.5037\nEpoch 111/160\n\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.6784 - loss: 1.9016 - val_accuracy: 0.7047 - val_loss: 1.4923\nEpoch 112/160\n\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.6951 - loss: 1.7734 - val_accuracy: 0.7010 - val_loss: 1.5145\nEpoch 113/160\n\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.7206 - loss: 1.6696 - val_accuracy: 0.6826 - val_loss: 1.5426\nEpoch 114/160\n\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.7103 - loss: 1.7810 - val_accuracy: 0.6789 - val_loss: 1.5109\nEpoch 115/160\n\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.7155 - loss: 1.7456 - val_accuracy: 0.7083 - val_loss: 1.5620\nEpoch 116/160\n\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.7411 - loss: 1.6436 - val_accuracy: 0.6716 - val_loss: 1.5817\nEpoch 117/160\n\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.7004 - loss: 1.8237 - val_accuracy: 0.7108 - val_loss: 1.4938\nEpoch 118/160\n\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.7208 - loss: 1.6758 - val_accuracy: 0.7157 - val_loss: 1.4739\nEpoch 119/160\n\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.7240 - loss: 1.7136 - val_accuracy: 0.6998 - val_loss: 1.5213\nEpoch 120/160\n\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.7106 - loss: 1.7857 - val_accuracy: 0.7071 - val_loss: 1.5068\nEpoch 121/160\n\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.6953 - loss: 1.8215 - val_accuracy: 0.6985 - val_loss: 1.5135\nEpoch 122/160\n\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.6993 - loss: 1.7581 - val_accuracy: 0.6936 - val_loss: 1.5228\nEpoch 123/160\n\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.7246 - loss: 1.7250 - val_accuracy: 0.7071 - val_loss: 1.5405\nEpoch 124/160\n\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.7207 - loss: 1.7622 - val_accuracy: 0.7022 - val_loss: 1.5275\nEpoch 125/160\n\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.7427 - loss: 1.6479 - val_accuracy: 0.7132 - val_loss: 1.5153\nEpoch 126/160\n\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.7290 - loss: 1.7251 - val_accuracy: 0.6961 - val_loss: 1.5167\nEpoch 127/160\n\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.7265 - loss: 1.7076 - val_accuracy: 0.7194 - val_loss: 1.5064\nEpoch 128/160\n\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.7287 - loss: 1.7452 - val_accuracy: 0.6900 - val_loss: 1.5149\nEpoch 129/160\n\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.7649 - loss: 1.6267 - val_accuracy: 0.6850 - val_loss: 1.5419\nEpoch 130/160\n\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.7206 - loss: 1.7695 - val_accuracy: 0.6777 - val_loss: 1.5722\nEpoch 131/160\n\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.7404 - loss: 1.7713 - val_accuracy: 0.7181 - val_loss: 1.4972\nEpoch 132/160\n\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.7351 - loss: 1.6913 - val_accuracy: 0.6581 - val_loss: 1.6606\nEpoch 133/160\n\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.7486 - loss: 1.6790 - val_accuracy: 0.7194 - val_loss: 1.4998\nEpoch 134/160\n\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.7365 - loss: 1.7382 - val_accuracy: 0.7022 - val_loss: 1.5068\nEpoch 135/160\n\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.7420 - loss: 1.6677 - val_accuracy: 0.6961 - val_loss: 1.5639\nEpoch 136/160\n\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.7483 - loss: 1.6714 - val_accuracy: 0.7157 - val_loss: 1.5093\nEpoch 137/160\n\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.7401 - loss: 1.7079 - val_accuracy: 0.7230 - val_loss: 1.4826\nEpoch 138/160\n\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.7324 - loss: 1.7240 - val_accuracy: 0.7145 - val_loss: 1.4820\nEpoch 139/160\n\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.7369 - loss: 1.7146 - val_accuracy: 0.7194 - val_loss: 1.4633\nEpoch 139: early stopping\nRestoring model weights from the end of the best epoch: 99.\nâœ” Training done â€“ artefacts saved in .\n","output_type":"stream"},{"name":"stderr","text":"2025-06-14 12:55:12.952075: E tensorflow/core/framework/node_def_util.cc:676] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m26/26\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step\nHoldâ€‘out Hâ€‘F1 = 0.866\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"### ã€‹ã€‹ã€‹**Predict**","metadata":{}},{"cell_type":"code","source":"def predict(sequence: pl.DataFrame, demographics: pl.DataFrame) -> str:\n    df_seq = sequence.to_pandas()\n\n    df_seq['acc_mag'] = np.sqrt(df_seq['acc_x']**2 + df_seq['acc_y']**2 + df_seq['acc_z']**2)\n    df_seq['rot_angle'] = 2 * np.arccos(df_seq['rot_w'].clip(-1, 1))\n    df_seq['acc_mag_jerk'] = df_seq['acc_mag'].diff().fillna(0)\n    df_seq['rot_angle_vel'] = df_seq['rot_angle'].diff().fillna(0)\n    \n    for i in range(1, 6): \n        pixel_cols_tof = [f\"tof_{i}_v{p}\" for p in range(64)]\n        tof_sensor_data = df_seq[pixel_cols_tof].replace(-1, np.nan)\n        \n        df_seq[f'tof_{i}_mean'] = tof_sensor_data.mean(axis=1)\n        df_seq[f'tof_{i}_std']  = tof_sensor_data.std(axis=1)\n        df_seq[f'tof_{i}_min']  = tof_sensor_data.min(axis=1)\n        df_seq[f'tof_{i}_max']  = tof_sensor_data.max(axis=1)\n        \n    df_seq_reordered = pd.DataFrame(columns=final_feature_cols)\n    for col in final_feature_cols:\n        if col in df_seq.columns:\n            df_seq_reordered[col] = df_seq[col]\n\n    mat_unscaled = df_seq_reordered.ffill().bfill().fillna(0).values.astype('float32')\n    \n    mat_scaled = scaler.transform(mat_unscaled)\n    \n    pad_input = pad_sequences([mat_scaled], maxlen=pad_len, padding='post', truncating='post', dtype='float32')\n    \n    idx = int(model.predict(pad_input, verbose=0).argmax(1)[0])\n    return str(gesture_classes[idx])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-14T12:55:14.767101Z","iopub.execute_input":"2025-06-14T12:55:14.767365Z","iopub.status.idle":"2025-06-14T12:55:14.775856Z","shell.execute_reply.started":"2025-06-14T12:55:14.767345Z","shell.execute_reply":"2025-06-14T12:55:14.775081Z"}},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":"### ã€‹ã€‹ã€‹**Submit Inference server**","metadata":{}},{"cell_type":"code","source":"import kaggle_evaluation.cmi_inference_server\ninference_server = kaggle_evaluation.cmi_inference_server.CMIInferenceServer(predict)\n\nif os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n    inference_server.serve()\nelse:\n    inference_server.run_local_gateway(\n        data_paths=(\n            '/kaggle/input/cmi-detect-behavior-with-sensor-data/test.csv',\n            '/kaggle/input/cmi-detect-behavior-with-sensor-data/test_demographics.csv',\n        )\n    )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-14T12:55:14.777453Z","iopub.execute_input":"2025-06-14T12:55:14.777634Z","iopub.status.idle":"2025-06-14T12:55:16.607366Z","shell.execute_reply.started":"2025-06-14T12:55:14.777620Z","shell.execute_reply":"2025-06-14T12:55:16.606770Z"}},"outputs":[],"execution_count":9}]}